{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7405a000-c999-4442-8ce7-b51917e7f075",
   "metadata": {},
   "source": [
    "# 1. What is a Decision Tree?\n",
    "\n",
    "- It is a tree structure that represents possible decision paths and an outcome for each path\n",
    "- Commonly used for <u>Classification and Regression tasks </u> both\n",
    "\n",
    "## (a) Example: \n",
    "- Consider a very idiosyncratic(not very comprehensive) \"Guess the Animal\" decision tree:\n",
    "  > “I am thinking of an animal.”  \n",
    "  > “Does it have more than five legs?”  \n",
    "  > “No.”  \n",
    "  > “Is it delicious?”  \n",
    "  > “No.”  \n",
    "  > “Does it appear on the back of the Australian five-cent coin?”  \n",
    "  > “Yes.”  \n",
    "  > “Is it an echidna?”  \n",
    "  > “Yes, it is!”  \n",
    "\n",
    "- This corresponds to the path:\n",
    "  > “Not more than 5 legs” → “Not delicious” → “On the 5-cent coin” → “Echidna!”\r\n",
    "\n",
    "## (b) Key Features of Decision Trees:\n",
    "1. Easy to understand and explain. Very clear thus excellent for communicating with non-experts. (thus Interpretable)\n",
    "\n",
    "2. They can manage both numeric and categorical data. For example, \"number of legs\" is numeric, while \"delicious/not delicious\" is categorical. (thus Flexible)\n",
    "\n",
    "3. They can classify data even if some attributes are missing, offering flexibility in data processing.\n",
    "\n",
    "## (c) Challenges with Decision Trees\n",
    "1. Finding an optimal decision tree for a dataset is computationally difficult. Thus, we will focus on good-enough one, not optimal.\n",
    "\n",
    "2. It is very easy (and very bad) to build decision trees that are overfitted to the training data, and that don’t generalize well to unseen data.\n",
    "   > Methods like pruning and limiting tree depth help mitigate this risk.\n",
    "\n",
    "## (d) Types of Decision Trees\n",
    "1. Classification Trees: These trees produce categorical outputs. For example, deciding whether an animal is an echidna or a platypus.\n",
    "\n",
    "2. Regression Trees: These trees predict numeric outputs, such as estimating the price of a house based on various features.\n",
    "\n",
    "We will Focus on Classification Trees, with an emphasis on binary outputs, such as:\n",
    "\n",
    "- \"Should I hire this candidate?\"\n",
    "- \"Should I show this website visitor advertisement A or B?\"\n",
    "- \"Will eating this food from the office fridge make me sick?\"\n",
    "\n",
    "## (e) ID3 Algorithm\n",
    "- The chapter introduces the ID3 algorithm for learning a decision tree from labeled data.\n",
    "- This algorithm uses entropy and information gain to determine the best questions to ask at each node, leading to a structured and efficient decision tree\n",
    "\n",
    "## (f) DT Nomenclature\n",
    "![image](DT_fig.png).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0ad399-0579-4f60-afe3-c806d8288806",
   "metadata": {},
   "source": [
    "# 2. Entropy\n",
    "\n",
    "> - Entropy is a measure of <u>uncertainty or disorder in a dataset </u>   \n",
    "> - It helps <u>determine the best questions</u> to ask to split the data in a way  <u>that reduces uncertainty</u>\n",
    "\n",
    "## What's a Best Question?\n",
    "> - Decision trees are structures that represent a series of decision points\n",
    "> - With each Decision point/Question splitting the data into smaller subsets\n",
    "> - At each stage, some possibilities are eliminated, while others remain\n",
    "> - To build an effective decision tree, we need to decide - 'questions' and 'their order'\n",
    "> -  Ideally, we want questions that maximize information gain and reduce uncertainty about the final outcome  \n",
    "\n",
    "Choose best question:\n",
    "> 1. High Information Gain questions: If a question perfectly separates data into distinct classes (Good question)\n",
    "> 2. Low Information Gain: It it doesn't provide much new information or doesn't help distinguish between classes is likely not a good choice\n",
    "\n",
    "## Finding Entropy H(S)\n",
    "1. Dataset: $S = [(input, label)]$\n",
    "2. Classes: labels $C_1, C_2, ... C_n$\n",
    "3. Mathematically Entropy is,\n",
    "   $$ H(S) = -p_1.log_2(p_1) - ... - p_n . log_2(p_n)$$\n",
    "   - $p_i$ is proportion of data labled as $C_i$\n",
    "   - with the (standard) convention that 0 log 0 = 0.\n",
    "5. (Entropy) $\\alpha$ (Uncertainity)\n",
    "   > - Low Entropy: If all data points <u>belong to a single class</u>, there's no uncertainty, leading to low entropy.\n",
    "   > - High Entropy: If data points are <u>evenly spread across multiple classes</u>, there's high uncertainty, resulting\n",
    "   >   in high entropy.\n",
    "6. $- p_n . log_2(p_n)$ is always positive because $0<p_i<1$\n",
    "7. Entropy H(S) can be greater than 1. Depends on number of classes and distribution of class probabilities\n",
    "   > - For two classes we will see max Entropy less than 1  \n",
    "   > - For more than two classes it exceeds 1\n",
    "9. Let's plot  $- p . log_2(p)$ vs $p$ and see:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb16ed6d-f521-4f4c-8340-e73a93b09f61",
   "metadata": {},
   "source": [
    "## Plotting Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783b49f3-12f5-47a9-a918-72dad99a635b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "xs = [x/100 for x in range(1,101)] # class probabilities\n",
    "ys = [(-p * math.log2(p)) for p in xs \n",
    "      if p >0]\n",
    "xs = [0] + xs \n",
    "ys = [0] + ys\n",
    "\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 0.6)\n",
    "plt.xlabel('p')\n",
    "plt.ylabel('-p log(p)')\n",
    "plt.plot(xs, ys)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519bcf3-bfe9-43bc-9da2-b41def92efb0",
   "metadata": {},
   "source": [
    "## Code for finding Entropy of dataset\n",
    "- To find data Entropy we will follow these steps:\n",
    "> 1. Define common entropy function of a List of possibility ($p$)\n",
    "> 2. Find probability ($p$) of each class from dataset\n",
    "> 4. Find entropy of full dataset using 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4639f5c-3899-422a-b0d0-1dc7d5c83fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import math\n",
    "\n",
    "def entropy(class_probabilities: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Given a list of class probabilities, compute the entropy\n",
    "    \"\"\"\n",
    "    return sum(-p * math.log2(p) \n",
    "               for p in class_probabilities\n",
    "               if p > 0\n",
    "              )\n",
    "\n",
    "assert entropy([0.5, 0.5]) == 1  # evenly distributed data among two classes has high entropy/uncertainity\n",
    "assert entropy([1, 0]) == 0      # one class has all data thus entropy is minimum\n",
    "assert 0.81 < entropy([0.25, 0.75]) < 0.82 # less entropy than evenly distributed dataset amond two classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2bcd1b-830c-4f2c-89bf-a47c500bdebb",
   "metadata": {},
   "source": [
    "We find:\n",
    "> 1. More evenly the data is distributed : More is uncertainity/Entropy\n",
    "> 2. More certain the data is in one class : Less Entropy\n",
    "\n",
    "Now, Let's apply to our data format,   \n",
    "$$dataset = [(input, label)]$$ \n",
    "$$ S = List[label] = [S_1, S_2,..., S_n]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42495bd0-511a-42d0-9878-91970c310b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from collections import Counter\n",
    "\n",
    "def class_probabilities(labels: List[Any]) -> List[float]:\n",
    "    \"\"\" \n",
    "    Probability of each class in list of label\n",
    "    \"\"\"\n",
    "    total_counts = len(labels)\n",
    "    return[counts/total_counts \n",
    "           for counts in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labels: List[Any]) -> float:\n",
    "    return entropy(class_probabilities(labels))\n",
    "\n",
    "assert data_entropy(['a']) == 0   # Only one label means highly certain dataset\n",
    "assert data_entropy([True, False]) == 1 # Two evenly distributed dataset means highly uncertain dataset\n",
    "assert data_entropy([3, 4, 4, 4]) == entropy([0.25, 0.75]) # Medium entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a065e-8297-4bb8-a98e-0e5d8f937324",
   "metadata": {},
   "source": [
    "# 3. Entropy of a Partition\n",
    "\n",
    "- Partitioning is the process of <u>splitting a dataset into subsets</u>\n",
    "- In decision trees, <u>each question creates a new partition</u>, resulting in subsets of the data\n",
    "- Our Goal is to find questions that <u>create subsets with low entropy</u>\n",
    "- Means they lead to a more definitive answer or prediction\n",
    "\n",
    "## (a) Calculate Partition Entropy\n",
    "$$\n",
    "H = q_1 \\cdot H(S_1) + \\ldots + q_m \\cdot H(S_m)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $q_i$ is the proportion of the data in subset $S_i$ i.e. $$q_i = \\frac{len(subset)}{len(dataset)}$$\n",
    "- $H(S_i)$ is the entropy of subset $S_i$.\n",
    "\n",
    "- If the partition is good\n",
    "> - The weighted sum of the partition entropy should be less than the total entropy of dataset\n",
    "> - Indicating that the partition has reduced uncertainty in the data\n",
    "> - This reduction in uncertainty is what drives the decision-making process in a decision tree\n",
    "\n",
    "- If the weighted sum of the partition entropy were the same as the total entropy\n",
    "> - It would mean that the partition did not reduce uncertainty\n",
    "> - Indicating that the split was ineffective in distinguishing between classes\n",
    "> - This situation would suggest poor partitioning, where the original uncertainty remains after the split\n",
    "\n",
    "## (b) Overfitting in DT with partitioning\n",
    "\n",
    "- When an attribute has a large number of unique values partitioning by that attribute will lead to subsets with very low entropy (high certainty)\n",
    "- Model will rely too heavily on specific details in the training set that are not broadly applicable\n",
    "\n",
    "Example: Social Security Number (SSN)\n",
    "> - Consider a scenario where you're building a decision tree for a bank to predict which customers are likely to default on their mortgages\n",
    "> - If the dataset includes each customer's Social Security number (SSN), partitioning on SSN would create one-person subsets, each with zero entropy\n",
    "> - This means the partition is highly specific to the training data and doesn't generalize to other datasets\n",
    "\n",
    "- Therefore, we should probably try to avoid (or bucket) attributes with large numbers of possible values when creating decision trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0dad3-64f5-46be-a591-e4196365e057",
   "metadata": {},
   "source": [
    "## (c) Code for Partition Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2e8a966c-cdc0-458a-a038-a9287524a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy(subsets: List[List[Any]]) -> float:\n",
    "    \"\"\"\n",
    "    Returns the entropy from this partition of data into subsets\n",
    "    \"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "    return sum(data_entropy(subset) * len(subset) / total_count for subset in subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f09bb-7d81-43c3-b15d-0237cba35035",
   "metadata": {},
   "source": [
    "# 4. Creating a Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78d6275-ddbb-4b18-90ba-24696f7a324c",
   "metadata": {},
   "source": [
    "- We will build a decision tree to <u>determine if candidates interviewed well based on various attributes</u>.\n",
    "- The key to creating an effective tree is - choose the best questions to split the data, minimizing uncertainty (entropy) at each step\n",
    "\n",
    "## (a) Candidate Data attributes:\n",
    "> - Attribute 1: Level: Senior, Mid, Junior \n",
    "> - Attribute 2: Preferred Language: Java, Python, R\n",
    "> - Attribute 3: Tweets: Whether they are active on Twitter\n",
    "> - Attribute 4: PhD: Whether they hold a PhD\n",
    "> - Label: Did Well: Whether they interviewed well (target variable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "057df89d-6581-4ee5-bf55-2feb237130f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class for attributes\n",
    "from typing import Optional, NamedTuple\n",
    "\n",
    "class Candidate(NamedTuple):\n",
    "    level:str\n",
    "    lang: str\n",
    "    tweets: bool\n",
    "    phd: bool\n",
    "    did_well: Optional[bool] = None # means it can be either boolean or missing/none\n",
    "\n",
    "# level lang tweets phd did_well\n",
    "inputs = [Candidate('Senior', 'Java', False, False, False),\n",
    "Candidate('Senior', 'Java', False, True, False),\n",
    "Candidate('Mid', 'Python', False, False, True),\n",
    "Candidate('Junior', 'Python', False, False, True),\n",
    "Candidate('Junior', 'R', True, False, True),\n",
    "Candidate('Junior', 'R', True, True, False),\n",
    "Candidate('Mid', 'R', True, True, True),\n",
    "Candidate('Senior', 'Python', False, False, False),\n",
    "Candidate('Senior', 'R', True, False, True),\n",
    "Candidate('Junior', 'Python', True, False, True),\n",
    "Candidate('Senior', 'Python', True, True, True),\n",
    "Candidate('Mid', 'Python', False, True, True),\n",
    "Candidate('Mid', 'Java', True, False, True),\n",
    "Candidate('Junior', 'Python', False, True, False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb8a20-a722-4dba-a935-e8d975538a50",
   "metadata": {},
   "source": [
    "## (b) ID3 Algorithm - Greedy algorithm\n",
    "1. Calculate entropy of full dataset on label did_well\n",
    "   > - If all instances have the same label True/False, the entropy will be 0\n",
    "   > - And create a leaf node (end node) that predicts the label and stop.\n",
    "\n",
    "2. Check if there are no more attributes to split on\n",
    "   > - Create leaf node with most common value for did_well label i.e. True or False and stop.\n",
    "\n",
    "3. Now, if attributes are there to be splitted\n",
    "   > - Partition data based on each attribute\n",
    "   > - Calculate partition entropy of each attribute on label\n",
    "   > - Choose the attribute with lowest Entropy  \n",
    "   >   As it will have lowest uncertainty and be most useful split.\n",
    "   > - Name the decision node of chosen attribute\n",
    "\n",
    "4. Recursively build the tree\n",
    "   > - Apply same ID3 algorithm to each subset again\n",
    "\n",
    "\n",
    "- This is what’s known as a “greedy” algorithm because,\n",
    "> - At each step, it chooses the most immediately best option.\n",
    "> - Given a dataset, there may be a better tree with a worse-looking first move.\n",
    "> - If so, this algorithm won’t find it.\n",
    "> - Nonetheless, it is relatively easy to understand and implement, which makes it a good place to begin exploring decision trees.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31df6e65-8887-444a-aa58-43432247cc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition by Level: defaultdict(<class 'list'>, {'Senior': [Candidate(level='Senior', lang='Java', tweets=False, phd=False, did_well=False), Candidate(level='Senior', lang='Java', tweets=False, phd=True, did_well=False), Candidate(level='Senior', lang='Python', tweets=False, phd=False, did_well=False), Candidate(level='Senior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=True, phd=True, did_well=True)], 'Mid': [Candidate(level='Mid', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Mid', lang='R', tweets=True, phd=True, did_well=True), Candidate(level='Mid', lang='Python', tweets=False, phd=True, did_well=True), Candidate(level='Mid', lang='Java', tweets=True, phd=False, did_well=True)], 'Junior': [Candidate(level='Junior', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Junior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='R', tweets=True, phd=True, did_well=False), Candidate(level='Junior', lang='Python', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=True, did_well=False)]})\n",
      "partition by language: defaultdict(<class 'list'>, {'Java': [Candidate(level='Senior', lang='Java', tweets=False, phd=False, did_well=False), Candidate(level='Senior', lang='Java', tweets=False, phd=True, did_well=False), Candidate(level='Mid', lang='Java', tweets=True, phd=False, did_well=True)], 'Python': [Candidate(level='Mid', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=False, phd=False, did_well=False), Candidate(level='Junior', lang='Python', tweets=True, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=True, phd=True, did_well=True), Candidate(level='Mid', lang='Python', tweets=False, phd=True, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=True, did_well=False)], 'R': [Candidate(level='Junior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='R', tweets=True, phd=True, did_well=False), Candidate(level='Mid', lang='R', tweets=True, phd=True, did_well=True), Candidate(level='Senior', lang='R', tweets=True, phd=False, did_well=True)]})\n",
      "partition by tweets: defaultdict(<class 'list'>, {False: [Candidate(level='Senior', lang='Java', tweets=False, phd=False, did_well=False), Candidate(level='Senior', lang='Java', tweets=False, phd=True, did_well=False), Candidate(level='Mid', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=False, phd=False, did_well=False), Candidate(level='Mid', lang='Python', tweets=False, phd=True, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=True, did_well=False)], True: [Candidate(level='Junior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='R', tweets=True, phd=True, did_well=False), Candidate(level='Mid', lang='R', tweets=True, phd=True, did_well=True), Candidate(level='Senior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=True, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=True, phd=True, did_well=True), Candidate(level='Mid', lang='Java', tweets=True, phd=False, did_well=True)]})\n",
      "partition by phd: defaultdict(<class 'list'>, {False: [Candidate(level='Senior', lang='Java', tweets=False, phd=False, did_well=False), Candidate(level='Mid', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=False, did_well=True), Candidate(level='Junior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Senior', lang='Python', tweets=False, phd=False, did_well=False), Candidate(level='Senior', lang='R', tweets=True, phd=False, did_well=True), Candidate(level='Junior', lang='Python', tweets=True, phd=False, did_well=True), Candidate(level='Mid', lang='Java', tweets=True, phd=False, did_well=True)], True: [Candidate(level='Senior', lang='Java', tweets=False, phd=True, did_well=False), Candidate(level='Junior', lang='R', tweets=True, phd=True, did_well=False), Candidate(level='Mid', lang='R', tweets=True, phd=True, did_well=True), Candidate(level='Senior', lang='Python', tweets=True, phd=True, did_well=True), Candidate(level='Mid', lang='Python', tweets=False, phd=True, did_well=True), Candidate(level='Junior', lang='Python', tweets=False, phd=True, did_well=False)]})\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, TypeVar\n",
    "from collections import defaultdict\n",
    "T = TypeVar('T') # generic type for inputs\n",
    "def partition_by(inputs: List[T], attribute: str) -> Dict[Any, List[T]]:\n",
    "    \"\"\"\n",
    "    Partition the inputs into lists based on the specified attribute.\n",
    "    \"\"\"\n",
    "    partitions: Dict[Any, List[T]] = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = getattr(input, attribute) # value of the specified attribute\n",
    "        partitions[key].append(input) # add input to the correct partition\n",
    "    return partitions\n",
    "\n",
    "#let's see how it will work\n",
    "print(f\"partition by Level: {partition_by(inputs, 'level')}\")\n",
    "print(f\"partition by language: {partition_by(inputs, 'lang')}\")\n",
    "print(f\"partition by tweets: {partition_by(inputs, 'tweets')}\")\n",
    "print(f\"partition by phd: {partition_by(inputs, 'phd')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80f04817-592e-437f-bcf5-7b2e285c0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_entropy_by(inputs: List[Any],\n",
    "                         attribute: str,\n",
    "                         label_attribute: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the partition entropy corresponding to the given partition\n",
    "    \"\"\"\n",
    "    # partitions consist of our inputs\n",
    "    partitions: dict[Any, List[T]] = partition_by(inputs, attribute)  # get all dataset partitioned under 'attribute' \n",
    "    \n",
    "    # but partition_entropy needs just the class labels \n",
    "    labels = [[getattr(input, label_attribute) for input in partition]\n",
    "              for partition in partitions.values()]\n",
    "    return partition_entropy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09bd517f-863e-44df-b139-c264038bf6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6935361388961919"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_entropy_by(inputs, attribute='level', label_attribute='did_well')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17247f6e-15df-45a7-b1e0-c78f530e6eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition entropy for level 0.6935361388961919\n",
      "Partition entropy for lang 0.8601317128547441\n",
      "Partition entropy for tweets 0.7884504573082896\n",
      "Partition entropy for phd 0.8921589282623617\n"
     ]
    }
   ],
   "source": [
    "# Find minimum entropy partition \n",
    "\n",
    "for attribute in ['level', 'lang', 'tweets', 'phd']:\n",
    "    print(f\"Partition entropy for {attribute} {partition_entropy_by(inputs, attribute, label_attribute='did_well')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2861fdce-64b9-4c86-94a0-a614d95f2c3b",
   "metadata": {},
   "source": [
    "- 'Level' partition has minimum entropy\n",
    "- Make subtree for each possible 'level'\n",
    "- For every 'Mid' candidate\n",
    "> - did_well = True\n",
    "- For 'Senior' candidate ->\n",
    "> - Some 'True' some 'False'\n",
    "> - So, we need to find subtree under it again\n",
    "> - Find minimum entropy partition among 'lang', 'tweets', 'phd'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22a67917-3811-48f5-b7ff-32f97a97fab9",
   "metadata": {},
   "source": [
    "senior_inputs = [input for input in inputs if input.level == 'Senior']\n",
    "for attribute in ['lang', 'tweets', 'phd']:\n",
    "    print(f\"Entropy for {attribute} in Senior {partition_entropy_by(senior_inputs, attribute, 'did_well')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ceeae1-e10a-4366-a7be-bd358c262d87",
   "metadata": {},
   "source": [
    "- So, our next split under 'Senior' will be 'tweets'\n",
    "  > - All Senior-level who tweet did well.\n",
    "\n",
    "- We will do same for 'Junior' Candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04139753-95b6-4e88-9123-66145babed80",
   "metadata": {},
   "source": [
    "- The Decision tree will come out as:  \n",
    "\n",
    "                  level?\n",
    "                 /   |   \\\n",
    "           Senior   Mid   Junior\n",
    "            /        |      \\   \n",
    "         tweets?    Hire!    phd? \n",
    "          /  \\              /  \\\n",
    "       Yes   No            No    Yes\n",
    "        /      \\           |      |\n",
    "     Hire!    Don't hire   Hire!  Don't hire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a034e-9627-4a44-81de-387ed38bc7d8",
   "metadata": {},
   "source": [
    "# 5. Putting it all together\n",
    "\n",
    "- We will build the decision tree using ID3 algorithm explained above\n",
    "- Then classify data with built tree\n",
    "\n",
    "## (a) Decision tree representation\n",
    "\n",
    "The decision tree can be represented as a combination of:\n",
    "\n",
    "> 1. Leaf Nodes: Nodes that predict a single value or class.\n",
    "> 2. Split Nodes: Nodes that contain an attribute to split on, with subtrees for specific values of that attribute, and optionally a default value for unknown or unexpected attribute values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abf8c5fd-5299-413d-b1d9-c2fee37e49e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation of nodes\n",
    "from typing import NamedTuple, Any, Union\n",
    "\n",
    "class Leaf(NamedTuple):\n",
    "    value: Any\n",
    "\n",
    "class Split(NamedTuple):\n",
    "    attribute: str\n",
    "    subtrees: dict\n",
    "    default_value: Any = None  # default if unknown value\n",
    "    \n",
    "DecisionTree = Union[Leaf, Split]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a9c6fc-0f32-4d87-bbfd-1ac947134d0a",
   "metadata": {},
   "source": [
    "## (b) Building DT using ID3\n",
    "\n",
    "1. Unique Label: If all data points have same label, create 'leaf' node of that label, then stop.\n",
    "2. No Split Attribute: No more attributes present for splitting, create 'leaf' node that predict the most common label.\n",
    "3. Partition by Best Attribute: None of condition 1/2 applies then partition by least entropy attribute and create split node.\n",
    "4. Recursion: Apply the ID3 algorithm recursively to each partitioned subset, using the remaining attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55332132-a310-46b7-8b86-989810205c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_tree_id3(inputs: List[Any],\n",
    "                   split_attributes: List[str],\n",
    "                   target_attribute: str) -> DecisionTree:\n",
    "\n",
    "    # 1. Unique Label\n",
    "    label_counts = Counter(getattr(input, target_attribute) for input in inputs)\n",
    "    most_common_label = label_counts.most_common(1)[0][0]\n",
    "\n",
    "    # If all labels are same, create a leaf node\n",
    "    if len(label_counts) == 1:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # 2. If no more split attribute, create a leaf node with most common label\n",
    "    if not split_attributes:\n",
    "        return Leaf(most_common_label)\n",
    "\n",
    "    # 3. Partition by attribute \n",
    "    def split_entropy(attribute: str) -> float:\n",
    "        return partition_entropy_by(inputs, attribute, target_attribute)\n",
    "\n",
    "    best_attribute = min(split_attributes, key = split_entropy)\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "\n",
    "    new_attributes = [a for a in split_attributes if a != best_attribute]\n",
    "\n",
    "    # 4. Recursively build subtrees\n",
    "    subtrees = {\n",
    "        attribute_value: build_tree_id3(subset, new_attributes, target_attribute)\n",
    "        for attribute_value, subset in partitions.items()\n",
    "    }\n",
    "    # Create split node with best attribute and its subtrees\n",
    "    return Split(best_attribute, subtrees, default_value=most_common_label)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccac6b-9fcc-4252-856f-b4a287e9b905",
   "metadata": {},
   "source": [
    "## (c) Using the Decision Tree for Classification\n",
    "- To classify an input using the decision tree, the algorithm follows the tree's structure, moving through the decision nodes until it reaches a leaf node.\n",
    "  \n",
    "- If an attribute is unknown, the algorithm uses the 'default_value' in the Split node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f7a2d06-5f6e-423f-96d7-a7e1eba02d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree: DecisionTree, input: Any) -> Any:\n",
    "    \"\"\"\n",
    "    Classify the input using the given decision tree\n",
    "    \"\"\"\n",
    "    if isinstance(tree, Leaf):\n",
    "        return tree.value  # If it's a leaf node, return its value\n",
    "\n",
    "    subtree_key = getattr(input, tree.attribute)\n",
    "    \n",
    "    if subtree_key not in tree.subtrees:  # Unknown value, use default\n",
    "        return tree.default_value\n",
    "    \n",
    "    # Traverse the tree based on the attribute value\n",
    "    subtree = tree.subtrees[subtree_key]\n",
    "    return classify(subtree, input)  # Recursively classify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "febb081b-b56d-4587-99cd-3c5e913fcfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Build the decision tree\n",
    "tree = build_tree_id3(inputs, ['level', 'lang', 'tweets', 'phd'], 'did_well')\n",
    "\n",
    "# Test the classification\n",
    "print(classify(tree, Candidate(\"Junior\", \"Java\", True, False)))  # Should predict True\n",
    "print(classify(tree, Candidate(\"Junior\", \"Java\", True, True)))   # Should predict False\n",
    "print(classify(tree, Candidate(\"Intern\", \"Java\", True, True)))   # Should predict True (default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765b940-a049-4203-a30b-16dd3c7899b4",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1401d-ccf3-4855-ba15-b95e3550efe4",
   "metadata": {},
   "source": [
    "- Problem with any model fit -  Overfitting\n",
    "  \n",
    "- DTs have the same problems, given how closely they fit to training data\n",
    "\n",
    "**How to avoid Overfitting in DTs?**\n",
    "\n",
    "- Using **Random Forest** technique\n",
    "  > First, we build multiple trees from same data  \n",
    "  > Second, we combine output of all trees :\n",
    "  > - Regression problem - take average\n",
    "  > - Classification problem - Vote\n",
    "\n",
    "- How to make multiple trees from same data?\n",
    "  > 1. Creating trees from bootstrapped data\n",
    "  > 2. Instead of using best_attribute among List of all attributes, using random subset of attribute list and find best among them.\n",
    "\n",
    "- Let's see how can we create multiple trees using second method:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d71c6b74-bde2-4460-9167-ebe0207fd640",
   "metadata": {},
   "source": [
    "# if there are already few enough split candidates, look at all of them\n",
    "\n",
    "if len(split_candidates) <= self.num_split_candidates:\n",
    "sampled_split_candidates = split_candidates\n",
    "\n",
    "# otherwise pick a random sample\n",
    "\n",
    "else:\n",
    "sampled_split_candidates = random.sample(split_candidates,\n",
    "self.num_split_candidates)\n",
    "\n",
    "# now choose the best attribute only from those candidates\n",
    "\n",
    "best_attribute = min(sampled_split_candidates, key=split_entropy)\n",
    "partitions = partition_by(inputs, best_attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f6234-f1f9-4fce-9cc5-6578ab79afad",
   "metadata": {},
   "source": [
    "## Ensemble learning\n",
    "- The above method where we generate multiple random trees to get a balanced Decision Tree is actually an example of Emsemble learning.\n",
    "- Here, we combine several weak learners (typically high-bias, low-variance models) in order to produce an overall strong model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
